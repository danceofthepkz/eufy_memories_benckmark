#!/usr/bin/env python3
"""
Phase 1 + Phase 2 + Phase 3 + Phase 4 + Phase 5 + Phase 6 å®Œæ•´é›†æˆæµ‹è¯•
å±•ç¤ºå®Œæ•´çš„å¤„ç†æµç¨‹ï¼šè§†é¢‘å¤„ç† â†’ äº‹ä»¶èåˆ â†’ LLM ç”Ÿæˆæ—¥å¿— â†’ æ•°æ®åº“æŒä¹…åŒ– â†’ æ¯æ—¥æ€»ç»“ç”Ÿæˆ â†’ ç”¨æˆ·æ£€ç´¢
"""

import sys
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from workflow import (
    CV_Pipeline,
    Event_Fusion_Pipeline,
    LLM_Reasoning_Pipeline,
    Persistence_Pipeline,
    Daily_Summary_Pipeline,
    User_Retrieval_Pipeline
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤º Phase 1 â†’ Phase 2 â†’ Phase 3 â†’ Phase 4 â†’ Phase 5 â†’ Phase 6 çš„å®Œæ•´æµç¨‹"""
    logger.info("=" * 60)
    logger.info("Phase 1-6 å®Œæ•´é›†æˆæµ‹è¯•")
    logger.info("=" * 60)
    
    # ========== Phase 1-5: æ•°æ®å¤„ç†æµç¨‹ ==========
    logger.info("\n" + "=" * 60)
    logger.info("Phase 1-5: æ•°æ®å¤„ç†æµç¨‹")
    logger.info("=" * 60)
    
    project_root = Path('.')
    
    # Phase 1
    logger.info("\n[Phase 1] è§†è§‰æ‰«æä¸ç‰¹å¾æå–...")
    try:
        cv_pipeline = CV_Pipeline(
            dataset_json_path=str(project_root / 'memories_ai_benchmark' / 'long_mem_dataset.json'),
            videos_base_dir=str(project_root / 'memories_ai_benchmark' / 'videos'),
            yolo_model='yolov8n.pt',
            face_model_name='buffalo_l',
            reid_model_name='osnet_x1_0',
            enable_tracking=True
        )
        clip_objs = cv_pipeline.process_all_clips(max_clips=5)
        logger.info(f"âœ… Phase 1 å®Œæˆ: {len(clip_objs)} ä¸ª Clip_Obj")
    except Exception as e:
        logger.error(f"âŒ Phase 1 å¤±è´¥: {e}")
        return
    
    # Phase 2
    logger.info("\n[Phase 2] æ—¶ç©ºäº‹ä»¶åˆå¹¶...")
    try:
        fusion_pipeline = Event_Fusion_Pipeline(time_threshold=60)
        global_events = fusion_pipeline.run(clip_objs)
        logger.info(f"âœ… Phase 2 å®Œæˆ: {len(global_events)} ä¸ªå…¨å±€äº‹ä»¶")
    except Exception as e:
        logger.error(f"âŒ Phase 2 å¤±è´¥: {e}")
        return
    
    # Phase 3
    logger.info("\n[Phase 3] LLM è¯­ä¹‰ç”Ÿæˆ...")
    try:
        llm_pipeline = LLM_Reasoning_Pipeline()
        processed_events = llm_pipeline.process_events(global_events)
        logger.info(f"âœ… Phase 3 å®Œæˆ: {len(processed_events)} ä¸ªäº‹ä»¶å·²ç”Ÿæˆæ—¥å¿—")
    except Exception as e:
        logger.error(f"âŒ Phase 3 å¤±è´¥: {e}")
        return
    
    # Phase 4
    logger.info("\n[Phase 4] ç»“æ„åŒ–è½åº“...")
    try:
        persistence_pipeline = Persistence_Pipeline()
        saved_event_ids = persistence_pipeline.save_events(processed_events)
        logger.info(f"âœ… Phase 4 å®Œæˆ: {len(saved_event_ids)} ä¸ªäº‹ä»¶å·²ä¿å­˜åˆ°æ•°æ®åº“")
    except Exception as e:
        logger.error(f"âŒ Phase 4 å¤±è´¥: {e}")
        return
    
    # Phase 5
    logger.info("\n[Phase 5] æ¯æ—¥æ€»ç»“ç”Ÿæˆ...")
    try:
        summary_pipeline = Daily_Summary_Pipeline()
        if processed_events:
            first_event_date = processed_events[0]['start_time'].strftime('%Y-%m-%d')
            summary_pipeline.run_for_date(first_event_date, force_update=True)
            logger.info(f"âœ… Phase 5 å®Œæˆ: æ—¥æœŸ {first_event_date} çš„æ€»ç»“å·²ç”Ÿæˆ")
    except Exception as e:
        logger.error(f"âŒ Phase 5 å¤±è´¥: {e}")
        return
    
    # ========== Phase 6: ç”¨æˆ·æ£€ç´¢ ==========
    logger.info("\n" + "=" * 60)
    logger.info("Phase 6: ç”¨æˆ·æ£€ç´¢ä¸ RAG")
    logger.info("=" * 60)
    
    try:
        retrieval_pipeline = User_Retrieval_Pipeline(
            videos_base_dir=str(project_root / 'memories_ai_benchmark' / 'videos')
        )
        logger.info("âœ… Phase 6 Pipeline åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ Phase 6 Pipeline åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "9æœˆ1æ—¥é‚£å¤©ï¼Œçˆ¸çˆ¸å›å®¶çš„æ—¶å€™ç©¿ä»€ä¹ˆè¡£æœï¼Ÿ",
        "2025å¹´9æœˆ1æ—¥æœ‰ä»€ä¹ˆæ´»åŠ¨ï¼Ÿ",
    ]
    
    for idx, query in enumerate(test_queries, 1):
        logger.info(f"\n[æŸ¥è¯¢ #{idx}] {query}")
        try:
            result = retrieval_pipeline.answer(query)
            
            logger.info(f"\nğŸ“ å›ç­”:")
            logger.info(f"   {result['answer']}")
            logger.info(f"\nğŸ“Š ç»Ÿè®¡:")
            logger.info(f"   è¯æ®æ•°é‡: {result['evidence_count']}")
            logger.info(f"   åŒ…å«å›¾ç‰‡: {result['has_images']}")
            if result['has_images']:
                logger.info(f"   å›¾ç‰‡æ•°é‡: {len(result['images'])}")
                
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # ========== å®Œæˆ ==========
    logger.info("\n" + "=" * 60)
    logger.info("âœ… å®Œæ•´æµç¨‹æµ‹è¯•å®Œæˆï¼")
    logger.info("=" * 60)
    logger.info("\nğŸ’¡ æ•°æ®æµ:")
    logger.info("   Phase 1: è§†é¢‘ â†’ Clip_Obj")
    logger.info("   Phase 2: Clip_Obj â†’ Global_Event")
    logger.info("   Phase 3: Global_Event â†’ è‡ªç„¶è¯­è¨€æ—¥å¿—")
    logger.info("   Phase 4: Global_Event â†’ PostgreSQL æ•°æ®åº“")
    logger.info("   Phase 5: event_logs è¡¨ â†’ æ¯æ—¥æ€»ç»“ â†’ daily_summaries è¡¨")
    logger.info("   Phase 6: ç”¨æˆ·é—®é¢˜ â†’ æ•°æ®åº“æ£€ç´¢ â†’ RAG å›ç­”")


if __name__ == '__main__':
    main()

