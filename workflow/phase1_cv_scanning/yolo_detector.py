"""
æ¨¡å— 3: å¤šç›®æ ‡æ£€æµ‹æ¨¡å— (ROI Detector)
èŒè´£ï¼šæ‰¾å‡ºç”»é¢é‡Œæ‰€æœ‰çš„äººï¼Œå¹¶æŠŠä»–ä»¬æŠ å‡ºæ¥
"""

import cv2
import numpy as np
from ultralytics import YOLO
from typing import List, Tuple, Dict
import logging

logger = logging.getLogger(__name__)


class PersonCrop:
    """äººç‰©è£å‰ªå¯¹è±¡"""
    def __init__(self, image: np.ndarray, bbox: Tuple[int, int, int, int], confidence: float):
        """
        Args:
            image: è£å‰ªåçš„äººç‰©å›¾ç‰‡
            bbox: è¾¹ç•Œæ¡†åæ ‡ (x1, y1, x2, y2)
            confidence: æ£€æµ‹ç½®ä¿¡åº¦
        """
        self.image = image
        self.bbox = bbox  # (x1, y1, x2, y2)
        self.confidence = confidence
        self.x1, self.y1, self.x2, self.y2 = bbox
        self.width = self.x2 - self.x1
        self.height = self.y2 - self.y1
        self.area = self.width * self.height
        # è®¡ç®—ä¸­å¿ƒç‚¹ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦åœ¨ç”»é¢ä¸­å¿ƒï¼‰
        self.center_x = (self.x1 + self.x2) / 2
        self.center_y = (self.y1 + self.y2) / 2


class YoloDetector:
    """å¤šç›®æ ‡æ£€æµ‹æ¨¡å—"""
    
    def __init__(self, model_path: str = 'yolov8n.pt', conf_threshold: float = 0.5):
        """
        åˆå§‹åŒ– YOLO æ£€æµ‹å™¨
        
        Args:
            model_path: YOLO æ¨¡å‹è·¯å¾„
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        """
        logger.info(f"ğŸ”§ åŠ è½½ YOLO æ¨¡å‹: {model_path}")
        self.detector = YOLO(model_path)
        self.conf_threshold = conf_threshold
        logger.info("âœ… YOLO æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def detect_persons(self, frame: np.ndarray) -> List[PersonCrop]:
        """
        æ£€æµ‹ç”»é¢ä¸­çš„æ‰€æœ‰äººç‰©
        
        Args:
            frame: è¾“å…¥å¸§ï¼ˆBGR æ ¼å¼ï¼‰
            
        Returns:
            äººç‰©è£å‰ªå¯¹è±¡åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«è£å‰ªåçš„å›¾ç‰‡å’Œè¾¹ç•Œæ¡†ä¿¡æ¯
        """
        # è¿è¡Œ YOLOv8 (Class=0, Person)
        # YOLO å†…éƒ¨å·²ç»åŒ…å« NMS (éæå¤§å€¼æŠ‘åˆ¶)
        results = self.detector(frame, classes=0, verbose=False)
        
        person_crops = []
        
        for result in results:
            for box in result.boxes:
                # è·å–è¾¹ç•Œæ¡†åæ ‡ (x1, y1, x2, y2)
                x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                confidence = float(box.conf[0].cpu().numpy())
                
                # è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹
                if confidence < self.conf_threshold:
                    continue
                
                # è¿‡æ»¤å¤ªå°çš„æ£€æµ‹æ¡†
                if (x2 - x1) < 50 or (y2 - y1) < 50:
                    continue
                
                # ROI è£å‰ª (Cropping): æ ¹æ®åæ ‡å°†æ¯ä¸ªäººç‰©ä»å¤§å›¾ä¸­è£å‰ªæˆå°å›¾
                person_img = frame[y1:y2, x1:x2].copy()
                
                if person_img.size == 0:
                    continue
                
                # åˆ›å»º PersonCrop å¯¹è±¡
                crop = PersonCrop(
                    image=person_img,
                    bbox=(x1, y1, x2, y2),
                    confidence=confidence
                )
                
                person_crops.append(crop)
        
        logger.debug(f"ğŸ” æ£€æµ‹åˆ° {len(person_crops)} ä¸ªäººç‰©")
        
        return person_crops

