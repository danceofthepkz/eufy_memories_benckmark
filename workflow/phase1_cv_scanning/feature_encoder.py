"""
æ¨¡å— 4: åŒæ¨¡æ€ç‰¹å¾ç¼–ç æ¨¡å— (Dual-Feature Encoder)
èŒè´£ï¼šæŠŠå›¾ç‰‡å˜æˆå‘é‡ï¼ˆäººè„¸ + èº«ä½“ï¼‰
"""

import cv2
import numpy as np
import torch
from typing import Dict, Optional
import logging
from insightface.app import FaceAnalysis

logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥ torchreid
try:
    import torchreid
    TORCHREID_AVAILABLE = True
except ImportError:
    TORCHREID_AVAILABLE = False
    logger.warning("âš ï¸  torchreid æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€åŒ–çš„èº«ä½“ç‰¹å¾æå–")


class FeatureEncoder:
    """åŒæ¨¡æ€ç‰¹å¾ç¼–ç æ¨¡å—"""
    
    def __init__(self, face_model_name: str = 'buffalo_l', reid_model_name: str = 'osnet_x1_0'):
        """
        åˆå§‹åŒ–ç‰¹å¾ç¼–ç å™¨
        
        Args:
            face_model_name: InsightFace æ¨¡å‹åç§°
            reid_model_name: ReID æ¨¡å‹åç§°ï¼ˆå¦‚ 'osnet_x1_0', 'osnet_ibn_x1_0'ï¼‰
        """
        # Face Branch: åˆå§‹åŒ– ArcFace æ¨¡å‹
        logger.info(f"ğŸ”§ åŠ è½½ InsightFace æ¨¡å‹: {face_model_name}")
        try:
            self.face_analyzer = FaceAnalysis(
                name=face_model_name,
                providers=['CPUExecutionProvider']
            )
            self.face_analyzer.prepare(ctx_id=0, det_size=(640, 640))
            logger.info("âœ… InsightFace æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸  InsightFace æ¨¡å‹åŠ è½½å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
            self.face_analyzer = None
        
        # Body Branch: åˆå§‹åŒ– ReID æ¨¡å‹
        self.reid_model = None
        self.reid_model_name = reid_model_name
        
        if TORCHREID_AVAILABLE:
            try:
                logger.info(f"ğŸ”§ åŠ è½½ ReID æ¨¡å‹: {reid_model_name}")
                self.reid_model = self._load_reid_model(reid_model_name)
                logger.info("âœ… ReID æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                logger.warning(f"âš ï¸  ReID æ¨¡å‹åŠ è½½å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨ç®€åŒ–å®ç°")
                self.reid_model = None
        else:
            logger.warning("âš ï¸  torchreid æœªå®‰è£…ï¼Œä½¿ç”¨ç®€åŒ–çš„èº«ä½“ç‰¹å¾æå–")
            logger.info("   å®‰è£…å‘½ä»¤: pip install torchreid")
        
        logger.info("âœ… ç‰¹å¾ç¼–ç å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_reid_model(self, model_name: str = 'osnet_x1_0'):
        """
        åŠ è½½ ReID æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼ˆå¦‚ 'osnet_x1_0'ï¼‰
            
        Returns:
            ReID æ¨¡å‹å¯¹è±¡
        """
        # æ„å»ºæ¨¡å‹ï¼ˆä¸æŒ‡å®šç±»åˆ«æ•°ï¼Œåªç”¨äºç‰¹å¾æå–ï¼‰
        model = torchreid.models.build_model(
            name=model_name,
            num_classes=1,  # åªç”¨äºç‰¹å¾æå–ï¼Œç±»åˆ«æ•°ä¸é‡è¦
            loss='softmax',
            pretrained=True  # ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        )
        
        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        model.eval()
        
        # å¦‚æœæœ‰GPUï¼Œç§»åˆ°GPUä¸Š
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        
        logger.info(f"   ReID æ¨¡å‹è®¾å¤‡: {device}")
        
        return {
            'model': model,
            'device': device
        }
    
    def extract(self, person_crop) -> Dict[str, Optional[np.ndarray]]:
        """
        æå–äººè„¸å’Œèº«ä½“ç‰¹å¾
        
        Args:
            person_crop: PersonCrop å¯¹è±¡ï¼ŒåŒ…å«è£å‰ªåçš„äººç‰©å›¾ç‰‡
            
        Returns:
            ç‰¹å¾åŒ…: {
                'face_vec': np.ndarray (512ç»´) æˆ– None,
                'body_vec': np.ndarray (512ç»´æˆ–2048ç»´ï¼Œå–å†³äºæ¨¡å‹)
            }
        """
        img = person_crop.image
        
        # Face Branch (äººè„¸åˆ†æ”¯)
        face_vec = self._extract_face_feature(img)
        
        # Body Branch (èº¯å¹²åˆ†æ”¯)
        body_vec = self._extract_body_feature(img)
        
        return {
            'face_vec': face_vec,
            'body_vec': body_vec
        }
    
    def _extract_face_feature(self, img: np.ndarray) -> Optional[np.ndarray]:
        """
        æå–äººè„¸ç‰¹å¾ (ArcFace)
        
        Args:
            img: äººç‰©å›¾åƒ (BGR æ ¼å¼)
            
        Returns:
            512ç»´äººè„¸ç‰¹å¾å‘é‡ï¼Œå¦‚æœæœªæ£€æµ‹åˆ°äººè„¸æˆ–æ¸…æ™°åº¦ä¸å¤Ÿåˆ™è¿”å› None
        """
        if self.face_analyzer is None:
            # æ¨¡æ‹Ÿæ¨¡å¼ï¼š30% æ¦‚ç‡è¿”å›äººè„¸ç‰¹å¾
            if np.random.rand() > 0.7:
                face_emb = np.random.rand(512).astype(np.float32)
                face_emb = face_emb / (np.linalg.norm(face_emb) + 1e-8)
                return face_emb
            return None
        
        try:
            # æ£€æµ‹äººè„¸
            faces = self.face_analyzer.get(img)
            
            if len(faces) == 0:
                return None
            
            # é€‰æ‹©æœ€å¤§çš„äººè„¸ï¼ˆé€šå¸¸è´¨é‡æœ€å¥½ï¼‰
            face = max(faces, key=lambda f: (f.bbox[2] - f.bbox[0]) * (f.bbox[3] - f.bbox[1]))
            
            # æ£€æŸ¥äººè„¸æ¸…æ™°åº¦ï¼ˆé€šè¿‡æ£€æµ‹ç½®ä¿¡åº¦ï¼‰
            # å¦‚æœæ¸…æ™°åº¦ > é˜ˆå€¼ï¼Œæå–ç‰¹å¾
            if hasattr(face, 'det_score') and face.det_score < 0.5:
                return None
            
            # æå– 512ç»´å‘é‡
            face_emb = face.embedding.astype(np.float32)
            
            # å½’ä¸€åŒ–
            face_emb = face_emb / (np.linalg.norm(face_emb) + 1e-8)
            
            return face_emb
            
        except Exception as e:
            logger.warning(f"âš ï¸  äººè„¸ç‰¹å¾æå–å¤±è´¥: {e}")
            return None
    
    def _extract_body_feature(self, img: np.ndarray) -> np.ndarray:
        """
        æå–èº«ä½“ç‰¹å¾ (ReID)
        
        Args:
            img: äººç‰©å›¾åƒ (BGR æ ¼å¼)
            
        Returns:
            èº«ä½“ç‰¹å¾å‘é‡ï¼ˆOSNet é€šå¸¸æ˜¯ 512 ç»´ï¼Œä½†æˆ‘ä»¬ä¼šæ‰©å±•åˆ° 2048 ç»´ä»¥ä¿æŒå…¼å®¹æ€§ï¼‰
        """
        if self.reid_model is not None:
            # ä½¿ç”¨çœŸæ­£çš„ ReID æ¨¡å‹
            return self._extract_with_reid_model(img)
        
        # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ç®€åŒ–å®ç°
        return self._extract_simple_body_feature(img)
    
    def _extract_with_reid_model(self, img: np.ndarray) -> np.ndarray:
        """
        ä½¿ç”¨çœŸæ­£çš„ ReID æ¨¡å‹æå–ç‰¹å¾
        
        Args:
            img: äººç‰©å›¾åƒ (BGR æ ¼å¼)
            
        Returns:
            2048ç»´èº«ä½“ç‰¹å¾å‘é‡
        """
        try:
            model = self.reid_model['model']
            device = self.reid_model['device']
            
            # é¢„å¤„ç†å›¾åƒ
            # ReID æ¨¡å‹é€šå¸¸éœ€è¦ RGB æ ¼å¼ï¼Œå°ºå¯¸ä¸º (256, 128)
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img_resized = cv2.resize(img_rgb, (128, 256))  # (width, height)
            
            # è½¬æ¢ä¸º torch tensor
            # å½’ä¸€åŒ–åˆ° [0, 1] ç„¶åæ ‡å‡†åŒ–
            img_tensor = torch.from_numpy(img_resized).float()
            img_tensor = img_tensor.permute(2, 0, 1)  # HWC -> CHW
            img_tensor = img_tensor / 255.0
            
            # ImageNet æ ‡å‡†åŒ–
            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
            img_tensor = (img_tensor - mean) / std
            
            # æ·»åŠ  batch ç»´åº¦
            img_tensor = img_tensor.unsqueeze(0).to(device)
            
            # æå–ç‰¹å¾
            with torch.no_grad():
                features = model(img_tensor)
                # è·å–ç‰¹å¾å‘é‡ï¼ˆé€šå¸¸æ˜¯æœ€åä¸€å±‚ä¹‹å‰ï¼‰
                if isinstance(features, tuple):
                    features = features[0]
                features = features.cpu().numpy().flatten()
            
            # OSNet é€šå¸¸è¾“å‡º 512 ç»´ç‰¹å¾
            # ä¸ºäº†ä¿æŒä¸æ•°æ®åº“çš„å…¼å®¹æ€§ï¼ˆ2048ç»´ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥ï¼š
            # 1. ç›´æ¥ä½¿ç”¨ 512 ç»´ï¼ˆéœ€è¦ä¿®æ”¹æ•°æ®åº“schemaï¼‰
            # 2. æ‰©å±•åˆ° 2048 ç»´ï¼ˆå½“å‰æ–¹æ¡ˆï¼‰
            
            feature_dim = len(features)
            
            if feature_dim < 2048:
                # æ‰©å±•åˆ° 2048 ç»´ï¼ˆé€šè¿‡é‡å¤å’Œå½’ä¸€åŒ–ï¼‰
                # æ–¹æ³•ï¼šå°†ç‰¹å¾é‡å¤å¤šæ¬¡ï¼Œç„¶åå½’ä¸€åŒ–
                repeat_times = (2048 // feature_dim) + 1
                extended_features = np.tile(features, repeat_times)[:2048]
                # å½’ä¸€åŒ–
                extended_features = extended_features.astype(np.float32)
                extended_features = extended_features / (np.linalg.norm(extended_features) + 1e-8)
                return extended_features
            elif feature_dim > 2048:
                # æˆªæ–­åˆ° 2048 ç»´
                features = features[:2048].astype(np.float32)
                features = features / (np.linalg.norm(features) + 1e-8)
                return features
            else:
                # æ­£å¥½ 2048 ç»´
                features = features.astype(np.float32)
                features = features / (np.linalg.norm(features) + 1e-8)
                return features
                
        except Exception as e:
            logger.warning(f"âš ï¸  ReID æ¨¡å‹ç‰¹å¾æå–å¤±è´¥: {e}ï¼Œé™çº§åˆ°ç®€åŒ–å®ç°")
            return self._extract_simple_body_feature(img)
    
    def _extract_simple_body_feature(self, img: np.ndarray) -> np.ndarray:
        """
        ç®€åŒ–çš„èº«ä½“ç‰¹å¾æå–ï¼ˆé™çº§æ–¹æ¡ˆï¼‰
        
        Args:
            img: äººç‰©å›¾åƒ (BGR æ ¼å¼)
            
        Returns:
            2048ç»´èº«ä½“ç‰¹å¾å‘é‡
        """
        # Resize åˆ° ReID æ ‡å‡†å°ºå¯¸
        img_resized = cv2.resize(img, (128, 256))
        img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)
        
        # æå–ç›´æ–¹å›¾ç‰¹å¾
        hist = cv2.calcHist([img_gray], [0], None, [256], [0, 256])
        hist = hist.flatten() / (hist.sum() + 1e-8)  # å½’ä¸€åŒ–
        
        # é¢œè‰²ç‰¹å¾ (HSV)
        hsv = cv2.cvtColor(img_resized, cv2.COLOR_BGR2HSV)
        h_hist = cv2.calcHist([hsv], [0], None, [180], [0, 180]).flatten()
        s_hist = cv2.calcHist([hsv], [1], None, [256], [0, 256]).flatten()
        
        # ç»„åˆç‰¹å¾
        simple_features = np.concatenate([hist, h_hist, s_hist])
        
        # æ‰©å±•åˆ° 2048 ç»´
        if len(simple_features) < 2048:
            # ä½¿ç”¨å¡«å……
            padding = np.random.randn(2048 - len(simple_features)) * 0.01
            body_emb = np.concatenate([simple_features, padding])
        else:
            body_emb = simple_features[:2048]
        
        # å½’ä¸€åŒ–
        body_emb = body_emb.astype(np.float32)
        body_emb = body_emb / (np.linalg.norm(body_emb) + 1e-8)
        
        return body_emb
